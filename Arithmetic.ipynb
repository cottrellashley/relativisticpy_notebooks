{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e26a6bff-1b43-4acb-8cf1-919d01cabd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "553d48b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(2, 3), match='/'>,\n",
       " <re.Match object; span=(4, 5), match=')'>,\n",
       " <re.Match object; span=(5, 6), match='*'>,\n",
       " <re.Match object; span=(31, 32), match='+'>,\n",
       " <re.Match object; span=(41, 42), match='*'>,\n",
       " <re.Match object; span=(42, 43), match='('>,\n",
       " <re.Match object; span=(48, 49), match='*'>,\n",
       " <re.Match object; span=(58, 59), match='+'>,\n",
       " <re.Match object; span=(64, 65), match='*'>,\n",
       " <re.Match object; span=(74, 75), match='-'>,\n",
       " <re.Match object; span=(80, 81), match='*'>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(string):\n",
    "    string = string.replace(' ', '')\n",
    "    return [ i for i in re.finditer('(\\+|\\-|((?<=[^a-z])\\((?=[^a-z]))|((?<=[^a-z])\\)(?=[^a-z]))|\\*|\\/)', string) if i]\n",
    "input_box = '(1/2)*function(my, god, it, works)+ G^{a}^{b}*(D_{c}*G_{b}_{d} + D_{d}*G_{b}_{c} - D_{b}*G_{c}_{d})'\n",
    "tokenize(input_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(',\n",
       " <__main__.MathJSON at 0x107d5da00>,\n",
       " '/',\n",
       " <__main__.MathJSON at 0x107d5d880>,\n",
       " ')',\n",
       " '*',\n",
       " 'function',\n",
       " '(',\n",
       " 'my,god,it,works',\n",
       " ')',\n",
       " '+',\n",
       " <__main__.MathJSON at 0x107d5d8e0>,\n",
       " '*',\n",
       " '(',\n",
       " <__main__.MathJSON at 0x107d5d040>,\n",
       " '*',\n",
       " <__main__.MathJSON at 0x107d5d220>,\n",
       " '+',\n",
       " <__main__.MathJSON at 0x107d5d1c0>,\n",
       " '*',\n",
       " <__main__.MathJSON at 0x107d5d160>,\n",
       " '-',\n",
       " <__main__.MathJSON at 0x107d5d310>,\n",
       " '*',\n",
       " <__main__.MathJSON at 0x107d5d2e0>,\n",
       " ')']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StringToMathJson:\n",
    "    def __init__(self, string):\n",
    "        self.string = string\n",
    "        self.OpBehaviour = namedtuple('OpBehaviour', 'priority lmbd')\n",
    "        self.operations = {\"+\": self.OpBehaviour(0, lambda x, y: y+x),\n",
    "                           \"-\": self.OpBehaviour(0, lambda x, y: y-x),\n",
    "                           \"/\": self.OpBehaviour(1, lambda x, y: y/x),\n",
    "                           \"*\": self.OpBehaviour(1, lambda x, y: y*x),\n",
    "                           \"^\": self.OpBehaviour(2, lambda x, y: y**x)}\n",
    "\n",
    "    def tokenize(self):\n",
    "        string = self.string.replace(' ', '')\n",
    "        return [ i for i in re.split('(\\+|\\-|\\(|\\)|\\*|\\/)', string) if i]\n",
    "\n",
    "    def match_tensors(self, i):\n",
    "        string = i\n",
    "        pattern = lambda x : \"([a-zA-Z]+)([_^]\\{[a-zA-Z]+\\}|[_^]\\{[a-zA-Z]+\\=[0-9]}){\" + str(x) + \"}(?=(\\*|\\)|\\+|\\-|\\/|$))\"\n",
    "        Total = [[x for x in re.finditer(pattern(j), string)] for j in range(1, 11)]\n",
    "        return [tensor.group() for nested in Total for tensor in nested]\n",
    "\n",
    "    def match_operators(self, i):\n",
    "        \"\"\"\n",
    "            Make checks as to what the name of the function is:\n",
    "                - Integrate\n",
    "                - solve\n",
    "                - diff\n",
    "                - subs\n",
    "                or just declared functions\n",
    "                - f(x)\n",
    "                - etc...\n",
    "            Then, make checks on the names and structure of the parameters.\n",
    "            And finally parse the object into the relevant sympy object and return it into the MathJSON object.\n",
    "        \"\"\"\n",
    "        Input = i.replace(' ', '')\n",
    "        Function = '(?<![a-zA-Z])' + '([a-zA-Z]+)' + '(\\(([a-z]+\\))' + '|' + '\\(([a-z]+\\,)*[a-z]\\))'\n",
    "        return [x for x in re.finditer(Function, Input)]\n",
    "\n",
    "    def json_wrapped_token(self):\n",
    "        tokens = self.tokenize()\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] not in ['+','-','/','(',')','*']:\n",
    "                if bool(self.match_operators(tokens[i])):\n",
    "                    tokens[i] = MathJSON({\"operators\" : tokens[i]})\n",
    "                elif bool(self.match_tensors(tokens[i])):\n",
    "                    tokens[i] = MathJSON({\"tensor_string_representation\" : tokens[i]})\n",
    "                elif bool(re.match('[0-9]+', tokens[i].replace('.','',1))):\n",
    "                    tokens[i] = MathJSON({\"number\" : tokens[i]})\n",
    "        return tokens\n",
    "\n",
    "    def to_rpn(self):\n",
    "        tokens = self.json_wrapped_token()\n",
    "        rpn_tokens = []\n",
    "        op_stack = []\n",
    "\n",
    "        for token in tokens:\n",
    "            # Add number to rpn tokens\n",
    "            if isinstance(token, MathJSON):\n",
    "                rpn_tokens.append(token)\n",
    "            # Add opening bracket to operation stack\n",
    "            elif token == \"(\":\n",
    "                op_stack.append(token)\n",
    "            # Consumes all operations until matching opening bracket\n",
    "            elif token == \")\":\n",
    "                while op_stack[-1] != \"(\":\n",
    "                    rpn_tokens.append(op_stack.pop())\n",
    "                op_stack.pop()\n",
    "            elif token in list(self.operations.keys()):\n",
    "                try:\n",
    "                    # Check if we have operations that have higher priority on\n",
    "                    # the op_stack and add them to rpn_tokens so that they are evaluated first:\n",
    "                    token_priority = self.operations[token].priority\n",
    "                    while op_stack[-1] != \"(\" and self.operations[op_stack[-1]].priority >= token_priority:\n",
    "                        rpn_tokens.append(op_stack.pop())\n",
    "                except IndexError:  # op_stack is empty\n",
    "                    pass\n",
    "                # Add the current operation to the op_stack:\n",
    "                op_stack.append(token)\n",
    "\n",
    "        # Add remaining operations to rpn tokens\n",
    "        while len(op_stack) != 0:\n",
    "            rpn_tokens.append(op_stack.pop())\n",
    "\n",
    "        return rpn_tokens\n",
    "\n",
    "    def calculate(self):\n",
    "        rpn_tokens = self.to_rpn()\n",
    "        val_stack = []\n",
    "\n",
    "        for token in rpn_tokens:\n",
    "            if isinstance(token, MathJSON):\n",
    "                val_stack.append(token)\n",
    "            elif token in list(self.operations.keys()):\n",
    "                args = []\n",
    "                for x in range(self.operations[token].lmbd.__code__.co_argcount):\n",
    "                    # If this throws an error user didn't give enough args\n",
    "                    args.append(val_stack.pop())\n",
    "                result = self.operations[token].lmbd(*args)\n",
    "                val_stack.append(result)\n",
    "\n",
    "        # If the value stack is bigger than one we probably made an error with the input\n",
    "        assert len(val_stack) == 1\n",
    "        return val_stack[0]\n",
    "\n",
    "\n",
    "\n",
    "input_box = '(1/2)*function(my, god, it, works)+ G^{a}^{b}*(D_{c}*G_{b}_{d} + D_{d}*G_{b}_{c} - D_{b}*G_{c}_{d})'\n",
    "StringToMathJson(input_box).json_wrapped_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "29a7eae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/2597060643.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0minput_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(1/2)*G^{a}^{b}*(D_{c}*G_{b}_{d} + D_{d}*G_{b}_{c} - D_{b}*G_{c}_{d})'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mStringToMathJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjectJson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/2597060643.py\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# If this throws an error user didn't give enough args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmbd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mval_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "class StringToMathJson:\n",
    "    def __init__(self, string):\n",
    "        self.string = string\n",
    "        self.OpBehaviour = namedtuple('OpBehaviour', 'priority lmbd')\n",
    "        self.operation_weight = { \"+\" : 0, \"-\" : 0, \"/\" : 1, \"*\" : 1, \"^\" : 2}\n",
    "        self.operations = {\"+\": self.OpBehaviour(0, lambda x, y: y+x),\n",
    "                           \"-\": self.OpBehaviour(0, lambda x, y: y-x),\n",
    "                           \"/\": self.OpBehaviour(1, lambda x, y: y/x),\n",
    "                           \"*\": self.OpBehaviour(1, lambda x, y: y*x),\n",
    "                           \"^\": self.OpBehaviour(2, lambda x, y: y**x)}\n",
    "\n",
    "    def tokenize(self):\n",
    "        string = self.string.replace(' ', '')\n",
    "        return [ i for i in re.split('(\\+|\\-|\\(|\\)|\\*|\\/)', string) if i]\n",
    "\n",
    "    def match_tensors(self, i):\n",
    "        string = i\n",
    "        pattern = lambda x : \"([a-zA-Z]+)([_^]\\{[a-zA-Z]+\\}|[_^]\\{[a-zA-Z]+\\=[0-9]}){\" + str(x) + \"}(?=(\\*|\\)|\\+|\\-|\\/|$))\"\n",
    "        Total = [[x for x in re.finditer(pattern(j), string)] for j in range(1, 11)]\n",
    "        return [tensor.group() for nested in Total for tensor in nested]\n",
    "\n",
    "    def match_operators(self, i):\n",
    "        \"\"\"\n",
    "            Make checks as to what the name of the function is:\n",
    "                - Integrate\n",
    "                - solve\n",
    "                - diff\n",
    "                - subs\n",
    "                or just declared functions\n",
    "                - f(x)\n",
    "                - etc...\n",
    "            Then, make checks on the names and structure of the parameters.\n",
    "            And finally parse the object into the relevant sympy object and return it into the MathJSON object.\n",
    "        \"\"\"\n",
    "        Input = i.replace(' ', '')\n",
    "        Function = '(?<![a-zA-Z])' + '([a-zA-Z]+)' + '(\\(([a-z]+\\))' + '|' + '\\(([a-z]+\\,)*[a-z]\\))'\n",
    "        return [x for x in re.finditer(Function, Input)]\n",
    "\n",
    "    def json_wrapped_token(self):\n",
    "        tokens = self.tokenize()\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] not in ['+','-','/','(',')','*']:\n",
    "                if bool(self.match_operators(tokens[i])):\n",
    "                    tokens[i] = MathJSON({\"operators\" : tokens[i]})\n",
    "                elif bool(self.match_tensors(tokens[i])):\n",
    "                    tokens[i] = MathJSON({\"tensor_string_representation\" : tokens[i]})\n",
    "                elif bool(re.match('[0-9]+', tokens[i].replace('.','',1))):\n",
    "                    tokens[i] = MathJSON({\"number\" : tokens[i]})\n",
    "        return tokens\n",
    "\n",
    "    def to_rpn(self):\n",
    "        tokens = self.json_wrapped_token()\n",
    "        rpn_tokens = []\n",
    "        op_stack = []\n",
    "\n",
    "        for token in tokens:\n",
    "            # Add number to rpn tokens\n",
    "            if isinstance(token, MathJSON):\n",
    "                rpn_tokens.append(token)\n",
    "            # Add opening bracket to operation stack\n",
    "            elif token == \"(\":\n",
    "                op_stack.append(token)\n",
    "            # Consumes all operations until matching opening bracket\n",
    "            elif token == \")\":\n",
    "                while op_stack[-1] != \"(\":\n",
    "                    rpn_tokens.append(op_stack.pop())\n",
    "                op_stack.pop()\n",
    "            elif token in list(self.operations.keys()):\n",
    "                try:\n",
    "                    # Check if we have operations that have higher priority on\n",
    "                    # the op_stack and add them to rpn_tokens so that they are evaluated first:\n",
    "                    token_priority = self.operation_weight[token]\n",
    "                    while op_stack[-1] != \"(\" and self.operation_weight[op_stack[-1]] >= token_priority:\n",
    "                        rpn_tokens.append(op_stack.pop())\n",
    "                except IndexError:  # op_stack is empty\n",
    "                    pass\n",
    "                # Add the current operation to the op_stack:\n",
    "                op_stack.append(token)\n",
    "\n",
    "        # Add remaining operations to rpn tokens\n",
    "        while len(op_stack) != 0:\n",
    "            rpn_tokens.append(op_stack.pop())\n",
    "\n",
    "        return rpn_tokens\n",
    "\n",
    "    def calculate(self):\n",
    "        rpn_tokens = self.to_rpn()\n",
    "        val_stack = []\n",
    "\n",
    "        for token in rpn_tokens:\n",
    "            if isinstance(token, MathJSON):\n",
    "                val_stack.append(token)\n",
    "            elif token in list(self.operations.keys()):\n",
    "                args = []\n",
    "                for x in range(self.operation_weight[token]):\n",
    "                    # If this throws an error user didn't give enough args\n",
    "                    args.append(val_stack.pop())\n",
    "                result = self.operations[token].lmbd(*args)\n",
    "                val_stack.append(result)\n",
    "\n",
    "        # If the value stack is bigger than one we probably made an error with the input\n",
    "        assert len(val_stack) == 1\n",
    "        return val_stack[0]\n",
    "\n",
    "\n",
    "\n",
    "input_box = '(1/2)*G^{a}^{b}*(D_{c}*G_{b}_{d} + D_{d}*G_{b}_{c} - D_{b}*G_{c}_{d})'\n",
    "StringToMathJson(input_box).calculate().objectJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85efc9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = {\"+\": lambda x, y: y+x,\n",
    "              \"-\":  lambda x, y: y-x,\n",
    "              \"/\": lambda x, y: y/x,\n",
    "              \"*\": lambda x, y: y*x,\n",
    "              \"^\": lambda x, y: y**x}\n",
    "list(operations.keys())\n",
    "bool(re.match('[0-9]+', '123|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8d5dded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpBehaviour = namedtuple('OpBehaviour', 'priority lmbd')\n",
    "\n",
    "operations = {\n",
    "    \"+\": OpBehaviour(0, lambda x, y: y+x),\n",
    "    \"-\": OpBehaviour(0, lambda x, y: y-x),\n",
    "    \"/\": OpBehaviour(1, lambda x, y: y/x),\n",
    "    \"*\": OpBehaviour(1, lambda x, y: y*x),\n",
    "    \"^\": OpBehaviour(2, lambda x, y: y**x),\n",
    "}\n",
    "\n",
    "operations[\"/\"].lmbd.__code__.co_argcount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89f25110",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 37",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/2846792352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexprList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1+7*(3+2)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/2846792352.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# \"|\".join(operations)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mrgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    445\u001b[0m                            not nested and not items))\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mAT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 raise source.error(\"nothing to repeat\",\n\u001b[0m\u001b[1;32m    670\u001b[0m                                    source.tell() - here + len(this))\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: nothing to repeat at position 37"
     ]
    }
   ],
   "source": [
    "def tokenize(string):\n",
    "    string = string.replace(\" \", \"\")\n",
    "\n",
    "    # What the fuck?\n",
    "    float_regex = \"\\d*\\.?\\d+|[\\(\\)]\"\n",
    "    for key in operations.keys():\n",
    "        if len(key) == 1:\n",
    "            float_regex += \"|\" + \"[\\\\\" + key + \"]\"\n",
    "        else:\n",
    "            float_regex += \"|\" + key\n",
    "        # \"|\".join(operations)\n",
    "        # pass\n",
    "    rgx = re.compile(float_regex)\n",
    "\n",
    "    results = rgx.finditer(string)\n",
    "    exprList = []\n",
    "    for reg in results:\n",
    "        start, end = reg.span()\n",
    "        exprList.append(string[start: end])\n",
    "    return exprList\n",
    "\n",
    "tokens = tokenize(\"1+7*(3+2)\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bbcf182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MathJSON:\n",
    "    def __init__(self, objectJson):\n",
    "        self.objectJson = objectJson\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        return MathJSON({ 'Add' : [self.objectJson, other.objectJson] })\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return MathJSON({ 'Mul' : [self.objectJson, other.objectJson] })\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return MathJSON({ 'Sub' : [self.objectJson, other.objectJson] })\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return MathJSON({ 'Div' : [self.objectJson, other.objectJson] })\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return MathJSON({ 'Eq' : [self.objectJson, other.objectJson] })\n",
    "\n",
    "parsed_tokens = [\n",
    "                '(',\n",
    "                 MathJSON({'integer' : '1'}),\n",
    "                 '/',\n",
    "                 MathJSON({'integer' : '2'}),\n",
    "                 ')',\n",
    "                 '*',\n",
    "                 MathJSON({'tensor_string_representation' : 'G^{a}^{b}'}),\n",
    "                 '*',\n",
    "                 '(',\n",
    "                 MathJSON({'tensor_string_representation' : 'D_{c}'}),\n",
    "                 '*',\n",
    "                 MathJSON({'tensor_string_representation' : 'G_{b}_{d}'}),\n",
    "                 '+',\n",
    "                 MathJSON({'tensor_string_representation' : 'D_{d}'}),\n",
    "                 '*',\n",
    "                 MathJSON({'tensor_string_representation' : 'G_{b}_{c}'}),\n",
    "                 '-',\n",
    "                 MathJSON({'tensor_string_representation' : 'D_{b}'}),\n",
    "                 '*',\n",
    "                 MathJSON({'tensor_string_representation' : 'G_{c}_{d}'}),\n",
    "                 ')'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "250317bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'priority'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/1441920721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrpn_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/1441920721.py\u001b[0m in \u001b[0;36mto_rpn\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# Check if we have operations that have higher priority on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;31m# the op_stack and add them to rpn_tokens so that they are evaluated first:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mtoken_priority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriority\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mop_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"(\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriority\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtoken_priority\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mrpn_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'priority'"
     ]
    }
   ],
   "source": [
    "def to_rpn(tokens):\n",
    "    rpn_tokens = []\n",
    "    op_stack = []\n",
    "\n",
    "    for token in tokens:\n",
    "        # Add number to rpn tokens\n",
    "        if isinstance(token, MathJSON):\n",
    "            rpn_tokens.append(token)\n",
    "        # Add opening bracket to operation stack\n",
    "        elif token == \"(\":\n",
    "            op_stack.append(token)\n",
    "        # Consumes all operations until matching opening bracket\n",
    "        elif token == \")\":\n",
    "            while op_stack[-1] != \"(\":\n",
    "                rpn_tokens.append(op_stack.pop())\n",
    "            op_stack.pop()\n",
    "        elif token in list(operations.keys()):\n",
    "            try:\n",
    "                # Check if we have operations that have higher priority on\n",
    "                # the op_stack and add them to rpn_tokens so that they are evaluated first:\n",
    "                token_priority = operations[token].priority\n",
    "                while op_stack[-1] != \"(\" and operations[op_stack[-1]].priority >= token_priority:\n",
    "                    rpn_tokens.append(op_stack.pop())\n",
    "            except IndexError:  # op_stack is empty\n",
    "                pass\n",
    "            # Add the current operation to the op_stack:\n",
    "            op_stack.append(token)\n",
    "\n",
    "    # Add remaining operations to rpn tokens\n",
    "    while len(op_stack) != 0:\n",
    "        rpn_tokens.append(op_stack.pop())\n",
    "\n",
    "    return rpn_tokens\n",
    "\n",
    "test = to_rpn(parsed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74556d35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MathJSON' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/3795544080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrpn_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mto_rpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/3795544080.py\u001b[0m in \u001b[0;36mto_rpn\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Add number to rpn tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mrpn_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Add opening bracket to operation stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/1g/_127qcc13ll334lvd9yl9vdc0000gn/T/ipykernel_18369/319495217.py\u001b[0m in \u001b[0;36mis_float\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MathJSON' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "def to_rpn(tokens):\n",
    "    rpn_tokens = []\n",
    "    op_stack = []\n",
    "\n",
    "    for token in tokens:\n",
    "        # Add number to rpn tokens\n",
    "        if (is_float(token)):\n",
    "            rpn_tokens.append(token)\n",
    "        # Add opening bracket to operation stack\n",
    "        elif token == \"(\":\n",
    "            op_stack.append(token)\n",
    "        # Consumes all operations until matching opening bracket\n",
    "        elif token == \")\":\n",
    "            while op_stack[-1] != \"(\":\n",
    "                rpn_tokens.append(op_stack.pop())\n",
    "            op_stack.pop()\n",
    "        elif token in list(operations.keys()):\n",
    "            try:\n",
    "                # Check if we have operations that have higher priority on\n",
    "                # the op_stack and add them to rpn_tokens so that they are evaluated first:\n",
    "                token_priority = operations[token].priority\n",
    "                while op_stack[-1] != \"(\" and operations[op_stack[-1]].priority >= token_priority:\n",
    "                    rpn_tokens.append(op_stack.pop())\n",
    "            except IndexError:  # op_stack is empty\n",
    "                pass\n",
    "            # Add the current operation to the op_stack:\n",
    "            op_stack.append(token)\n",
    "\n",
    "    # Add remaining operations to rpn tokens\n",
    "    while len(op_stack) != 0:\n",
    "        rpn_tokens.append(op_stack.pop())\n",
    "\n",
    "    return rpn_tokens\n",
    "\n",
    "to_rpn(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd4fa9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mul': [{'Mul': [{'Div': [{'integer': '1'}, {'integer': '2'}]},\n",
       "    {'tensor_string_representation': 'G^{a}^{b}'}]},\n",
       "  {'Sub': [{'Add': [{'Mul': [{'tensor_string_representation': 'D_{c}'},\n",
       "        {'tensor_string_representation': 'G_{b}_{d}'}]},\n",
       "      {'Mul': [{'tensor_string_representation': 'D_{d}'},\n",
       "        {'tensor_string_representation': 'G_{b}_{c}'}]}]},\n",
       "    {'Mul': [{'tensor_string_representation': 'D_{b}'},\n",
       "      {'tensor_string_representation': 'G_{c}_{d}'}]}]}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate(rpn_tokens):\n",
    "    val_stack = []\n",
    "\n",
    "    for token in rpn_tokens:\n",
    "        if isinstance(token, MathJSON):\n",
    "            val_stack.append(token)\n",
    "        elif token in list(operations.keys()):\n",
    "            args = []\n",
    "            for x in range(operations[token].lmbd.__code__.co_argcount):\n",
    "                # If this throws an error user didn't give enough args\n",
    "                args.append(val_stack.pop())\n",
    "            result = operations[token].lmbd(*args)\n",
    "            val_stack.append(result)\n",
    "\n",
    "    # If the value stack is bigger than one we probably made an error with the input\n",
    "    assert len(val_stack) == 1\n",
    "    return val_stack[0]\n",
    "\n",
    "calculate(test).objectJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54bfbae6-e9c8-4abb-b217-0d9c686fa917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_string(string):\n",
    "    tokenized = tokenize(string)\n",
    "    rpn = to_rpn(tokenized)\n",
    "    return calculate(rpn)\n",
    "\n",
    "calculate_string('1+1*(2-5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd249e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MathJson = {'Mul': [{'Mul': [{'Div': [{'integer': '1'}, {'integer': '2'}]},\n",
    "    {'tensor_string_representation': 'G^{a}^{b}'}]},\n",
    "  {'Sub': [{'Add': [{'Mul': [{'tensor_string_representation': 'D_{c}'},\n",
    "        {'tensor_string_representation': 'G_{b}_{d}'}]},\n",
    "      {'Mul': [{'tensor_string_representation': 'D_{d}'},\n",
    "        {'tensor_string_representation': 'G_{b}_{c}'}]}]},\n",
    "    {'Mul': [{'tensor_string_representation': 'D_{b}'},\n",
    "      {'tensor_string_representation': 'G_{c}_{d}'}]}]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Mul': [{'Mul': [{'Div': [{'integer': '1'}, {'integer': '2'}]},\n",
    "    {'tensor_string_representation': 'G^{a}^{b}'}]},\n",
    "  {'Sub': [{'Add': [{'Mul': [{'tensor_string_representation': 'D_{c}'},\n",
    "        {'tensor_string_representation': 'G_{b}_{d}'}]},\n",
    "      {'Mul': [{'tensor_string_representation': 'D_{d}'},\n",
    "        {'tensor_string_representation': 'G_{b}_{c}'}]}]},\n",
    "    {'Mul': [{'tensor_string_representation': 'D_{b}'},\n",
    "      {'tensor_string_representation': 'G_{c}_{d}'}]}]}]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
